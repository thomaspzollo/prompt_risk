{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.generate_outputs import hash_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2078443/1505285216.py:16: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(model_path)\n",
      "/tmp/ipykernel_2078443/1505285216.py:16: DtypeWarning: Columns (23) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(model_path)\n",
      "/tmp/ipykernel_2078443/1505285216.py:16: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(model_path)\n",
      "/tmp/ipykernel_2078443/1505285216.py:16: DtypeWarning: Columns (21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(model_path)\n",
      "/tmp/ipykernel_2078443/1505285216.py:16: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(model_path)\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"../output\"\n",
    "datasets = ['bigbio/meqsum', 'cnn_dailymail', 'full_chat', 'mbpp', 'red_team_chat', 'xsum']\n",
    "dfs = {}\n",
    "for dataset_ in datasets:\n",
    "    dataset = dataset_\n",
    "    # define output folder and cache csv path\n",
    "    dataset_dir = dataset.replace(\"/\", \"_\")\n",
    "    save_folder = os.path.join(output_dir, dataset_dir)\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    files = os.listdir(save_folder)\n",
    "    files = [f for f in files if f.endswith(\".csv\")]\n",
    "    files = [f for f in files if not f.endswith(\"embeddings.csv\")]\n",
    "    for f in files:\n",
    "        model_id = f.split(\"_predictions.csv\")[0]\n",
    "        model_path = os.path.join(save_folder, f)\n",
    "        df = pd.read_csv(model_path)\n",
    "        dfs[model_path] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['../output/bigbio_meqsum/tiiuae-falcon-7b-instruct_predictions.csv', '../output/bigbio_meqsum/tiiuae-falcon-40b-instruct_predictions.csv', '../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv', '../output/full_chat/google-flan-t5-xl_predictions.csv', '../output/full_chat/google-flan-t5-xxl_predictions.csv', '../output/mbpp/codellama-CodeLlama-7b-Instruct-hf_predictions.csv', '../output/red_team_chat/google-flan-t5-xl_predictions.csv', '../output/red_team_chat/google-flan-t5-xxl_predictions.csv', '../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select top 20 hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20 hypotheses for xsum/cnn_dailymail and full_chat/red_team_chat\n",
    "# by summing their scores \n",
    "datasets = ['cnn_dailymail',  'xsum', 'full_chat', 'red_team_chat']\n",
    "cnn_dailymail_hyps = dfs['../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv'].groupby(['hypothesis'])['rougeL'].mean()\n",
    "xsum_hyps = dfs['../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv'].groupby(['hypothesis'])['rougeL'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis\n",
      "{'instruction': \"Your goal is to provide a summarized version of the document's content in fewer words.\"}                    0.320253\n",
      "{'instruction': 'Your goal is to provide shorter versions of the documents that encompass the main ideas.'}                  0.295859\n",
      "{'instruction': 'Generate concise summaries that provide a quick overview of the document content.'}                         0.288168\n",
      "{'instruction': 'Create concise summaries that communicate the primary concepts in the documents.'}                          0.287793\n",
      "{'instruction': 'You are tasked with generating succinct summaries for the given documents.'}                                0.286266\n",
      "{'instruction': \"Your task involves producing compact summaries that convey the documents' core concepts.\"}                  0.285061\n",
      "{'instruction': 'Your objective is to create concise summaries of the provided documents.'}                                  0.284100\n",
      "{'instruction': 'Summarize the documents in a way that captures the essence of the original content.'}                       0.281232\n",
      "{'instruction': 'Create brief summaries that capture the essential information contained in the documents.'}                 0.281051\n",
      "{'instruction': 'The aim is to produce abridged summaries of the provided text documents.'}                                  0.280602\n",
      "{'instruction': 'Summarize the content of the documents to capture the essential meaning.'}                                  0.279377\n",
      "{'instruction': 'Produce succinct and informative summaries for each of the provided documents.'}                            0.279332\n",
      "{'instruction': 'Your task involves creating shortened versions of the documents while retaining essential information.'}    0.278410\n",
      "{'instruction': 'You are required to generate brief summaries that capture the key points of the documents.'}                0.277142\n",
      "{'instruction': 'Generate summarized versions of the documents that preserve the main ideas.'}                               0.275825\n",
      "{'instruction': 'Create brief yet comprehensive summaries of the provided documents.'}                                       0.275022\n",
      "{'instruction': 'Condense and encapsulate the main points of the documents in your summaries.'}                              0.273018\n",
      "{'instruction': 'Your task is to distill the documents into shorter versions while retaining key information.'}              0.272941\n",
      "{'instruction': \"Your goal is to perform a summarization task by condensing the document's content.\"}                        0.268024\n",
      "{'instruction': 'Create abridged summaries of the documents while maintaining coherence.'}                                   0.267323\n",
      "Name: rougeL, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "summed_hyp_scores = xsum_hyps + cnn_dailymail_hyps\n",
    "# sort by score and select top 20\n",
    "top_news_hyps = summed_hyp_scores.sort_values(ascending=False).head(20)\n",
    "print(top_news_hyps)\n",
    "top_news_hyps = [eval(x)['instruction'] for x in top_news_hyps.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Your goal is to provide a summarized version of the document's content in fewer words.\",\n",
       " 'Your goal is to provide shorter versions of the documents that encompass the main ideas.',\n",
       " 'Generate concise summaries that provide a quick overview of the document content.',\n",
       " 'Create concise summaries that communicate the primary concepts in the documents.',\n",
       " 'You are tasked with generating succinct summaries for the given documents.',\n",
       " \"Your task involves producing compact summaries that convey the documents' core concepts.\",\n",
       " 'Your objective is to create concise summaries of the provided documents.',\n",
       " 'Summarize the documents in a way that captures the essence of the original content.',\n",
       " 'Create brief summaries that capture the essential information contained in the documents.',\n",
       " 'The aim is to produce abridged summaries of the provided text documents.',\n",
       " 'Summarize the content of the documents to capture the essential meaning.',\n",
       " 'Produce succinct and informative summaries for each of the provided documents.',\n",
       " 'Your task involves creating shortened versions of the documents while retaining essential information.',\n",
       " 'You are required to generate brief summaries that capture the key points of the documents.',\n",
       " 'Generate summarized versions of the documents that preserve the main ideas.',\n",
       " 'Create brief yet comprehensive summaries of the provided documents.',\n",
       " 'Condense and encapsulate the main points of the documents in your summaries.',\n",
       " 'Your task is to distill the documents into shorter versions while retaining key information.',\n",
       " \"Your goal is to perform a summarization task by condensing the document's content.\",\n",
       " 'Create abridged summaries of the documents while maintaining coherence.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_news_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothesis\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to provide accurate information, share wisdom, and be friendly.'}                       1.111292\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to provide accurate information, share positivity, and be supportive.'}                 1.083162\n",
      "{'instruction': \"You are a helpful chatbot. You're committed to spreading kindness and providing accurate information.\"}                            1.073551\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to share insights, resources, and encouragement.'}                                      1.069509\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide users with accurate information and a friendly experience.'}                    1.064923\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on spreading positivity, sharing knowledge, and being kind.'}                             1.062406\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to offer guidance, practical tips, and emotional support.'}                                1.062389\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide users with accurate information, share insights, and encourage well-being.'}    1.060308\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to create connections, offer insights, and encourage positivity.'}                      1.058185\n",
      "{'instruction': \"You are a helpful chatbot. You're here to answer questions, offer advice, and create connections.\"}                                1.055472\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on promoting positivity and providing a safe space for conversation.'}                    1.054321\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide practical solutions and a listening ear.'}                                      1.054014\n",
      "{'instruction': 'You are a helpful chatbot. You aim to make each conversation meaningful, informative, and enjoyable.'}                             1.051957\n",
      "{'instruction': \"You are a helpful chatbot. You're here to make users' lives better by offering advice and helpful insights.\"}                      1.046930\n",
      "{'instruction': \"You are a helpful chatbot. You're dedicated to fostering a supportive and inclusive chat environment.\"}                            1.045508\n",
      "{'instruction': 'You are a helpful chatbot. You strive to create a positive atmosphere and engage in meaningful conversations.'}                    1.043115\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to make conversations engaging, informative, and enjoyable.'}                           1.041697\n",
      "{'instruction': \"You are a helpful chatbot. You're dedicated to fostering a sense of belonging, offering advice, and being a digital friend.\"}      1.039974\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to create connections, offer encouragement, and promote well-being.'}                      1.039860\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on creating a positive atmosphere, offering guidance, and spreading kindness.'}           1.037178\n",
      "Name: weqweasdas/hh_rlhf_rm_open_llama_3b_eval_reward_med_sigmoid, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# repeat for chat datasets\n",
    "full_chat_hyps = dfs['../output/full_chat/google-flan-t5-xxl_predictions.csv'].groupby(['hypothesis'])['weqweasdas/hh_rlhf_rm_open_llama_3b_eval_reward_med_sigmoid'].mean()\n",
    "red_team_chat_hyps = dfs['../output/red_team_chat/google-flan-t5-xxl_predictions.csv'].groupby(['hypothesis'])['weqweasdas/hh_rlhf_rm_open_llama_3b_eval_reward_med_sigmoid'].mean()\n",
    "\n",
    "summed_hyp_scores = full_chat_hyps + red_team_chat_hyps\n",
    "# sort by score and select top 20\n",
    "top_chat_hyps = summed_hyp_scores.sort_values(ascending=False).head(20)\n",
    "print(top_chat_hyps)\n",
    "top_chat_hyps = [eval(x)['instruction'] for x in top_chat_hyps.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You are a helpful chatbot. Your mission is to provide accurate information, share wisdom, and be friendly.',\n",
       " 'You are a helpful chatbot. Your purpose is to provide accurate information, share positivity, and be supportive.',\n",
       " \"You are a helpful chatbot. You're committed to spreading kindness and providing accurate information.\",\n",
       " 'You are a helpful chatbot. Your purpose is to share insights, resources, and encouragement.',\n",
       " 'You are a helpful chatbot. Your goal is to provide users with accurate information and a friendly experience.',\n",
       " 'You are a helpful chatbot. Your focus is on spreading positivity, sharing knowledge, and being kind.',\n",
       " 'You are a helpful chatbot. Your goal is to offer guidance, practical tips, and emotional support.',\n",
       " 'You are a helpful chatbot. Your goal is to provide users with accurate information, share insights, and encourage well-being.',\n",
       " 'You are a helpful chatbot. Your purpose is to create connections, offer insights, and encourage positivity.',\n",
       " \"You are a helpful chatbot. You're here to answer questions, offer advice, and create connections.\",\n",
       " 'You are a helpful chatbot. Your focus is on promoting positivity and providing a safe space for conversation.',\n",
       " 'You are a helpful chatbot. Your goal is to provide practical solutions and a listening ear.',\n",
       " 'You are a helpful chatbot. You aim to make each conversation meaningful, informative, and enjoyable.',\n",
       " \"You are a helpful chatbot. You're here to make users' lives better by offering advice and helpful insights.\",\n",
       " \"You are a helpful chatbot. You're dedicated to fostering a supportive and inclusive chat environment.\",\n",
       " 'You are a helpful chatbot. You strive to create a positive atmosphere and engage in meaningful conversations.',\n",
       " 'You are a helpful chatbot. Your mission is to make conversations engaging, informative, and enjoyable.',\n",
       " \"You are a helpful chatbot. You're dedicated to fostering a sense of belonging, offering advice, and being a digital friend.\",\n",
       " 'You are a helpful chatbot. Your goal is to create connections, offer encouragement, and promote well-being.',\n",
       " 'You are a helpful chatbot. Your focus is on creating a positive atmosphere, offering guidance, and spreading kindness.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_chat_hyps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check number generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39mcols)\n\u001b[1;32m      3\u001b[0m \u001b[39m# assert that all hypotheses have the same number of generations\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mset\u001b[39m(df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mhypothesis\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39msize())) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# cols = ['text', 'hypothesis', 'dataset', 'model_name_or_path', 'seed', 'task_id']\n",
    "# df = df.drop_duplicates(subset=cols)\n",
    "# # assert that all hypotheses have the same number of generations\n",
    "# assert len(set(df.groupby('hypothesis').size())) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/bigbio_meqsum/tiiuae-falcon-7b-instruct_predictions.csv 50\n",
      "../output/bigbio_meqsum/tiiuae-falcon-40b-instruct_predictions.csv 50\n",
      "../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv 40\n",
      "../output/full_chat/google-flan-t5-xl_predictions.csv 2\n",
      "../output/full_chat/google-flan-t5-xxl_predictions.csv 50\n",
      "../output/mbpp/codellama-CodeLlama-7b-Instruct-hf_predictions.csv 30\n",
      "../output/red_team_chat/google-flan-t5-xl_predictions.csv 2\n",
      "../output/red_team_chat/google-flan-t5-xxl_predictions.csv 50\n",
      "../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv 30\n"
     ]
    }
   ],
   "source": [
    "# tally up unique hypotheses per dataset\n",
    "for key in dfs.keys():\n",
    "    df = dfs[key]\n",
    "    print(key, df['hypothesis'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/bigbio_meqsum/tiiuae-falcon-7b-instruct_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\"}                                                              990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [2, 3]}                                    990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [6]}                                          990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [7, 5]}                                    990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [5]}                                   990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [3, 4]}                               990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [1, 2, 3]}                                                   990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [4, 8]}                            990\n",
      "{'instruction': 'You summarize user queries without missing any important details.', 'k_shot_idxs': [4, 1]}                                                                       990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.', 'k_shot_idxs': [9]}          990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\", 'k_shot_idxs': [5, 3, 7]}                                                                        990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [7, 2]}                                       990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [8, 9, 4]}                             990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\"}                                                           990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [9, 6, 8]}                            990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [3, 2]}                                                      990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [7, 1, 0]}                         990\n",
      "{'instruction': 'You summarize user queries without missing any important details.', 'k_shot_idxs': [2, 6, 1]}                                                                    990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.', 'k_shot_idxs': [6, 7]}       990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\", 'k_shot_idxs': [4, 8, 0]}                                                                        990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [1, 8, 4]}                                    990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [5, 1, 4]}                                 990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [2, 7]}                                990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [4]}                                  990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\", 'k_shot_idxs': [1, 3]}                                                                           990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.', 'k_shot_idxs': [1, 0, 3]}    990\n",
      "{'instruction': 'You summarize user queries without missing any important details.', 'k_shot_idxs': [4, 5, 3]}                                                                    990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [1, 6, 9]}                         990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\"}                                                       990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\"}                                                      990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\"}                                                                             990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\"}                                                   990\n",
      "{'instruction': 'You summarize user queries without missing any important details.'}                                                                                              990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.'}                              990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\"}                                                                                                  990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [1, 0, 4]}                                    990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [3]}                                       990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [1]}                                   990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [8, 1, 6]}                            990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [0]}                                                         990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [8]}                               990\n",
      "{'instruction': 'You summarize user queries without missing any important details.', 'k_shot_idxs': [0, 8, 3]}                                                                    990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.', 'k_shot_idxs': [8, 6, 3]}    990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\", 'k_shot_idxs': [9, 4]}                                                                           990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [2]}                                          990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [6, 5, 4]}                                 990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [1, 9]}                                990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [1, 5]}                               990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [7]}                                                         990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [2, 8, 1]}                                                   990\n",
      "Name: count, dtype: int64\n",
      "../output/bigbio_meqsum/tiiuae-falcon-40b-instruct_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\"}                                                              990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [2, 3]}                                    990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [6]}                                          990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [7, 5]}                                    990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [5]}                                   990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [3, 4]}                               990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [1, 2, 3]}                                                   990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [4, 8]}                            990\n",
      "{'instruction': 'You summarize user queries without missing any important details.', 'k_shot_idxs': [4, 1]}                                                                       990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.', 'k_shot_idxs': [9]}          990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\", 'k_shot_idxs': [5, 3, 7]}                                                                        990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [7, 2]}                                       990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [8, 9, 4]}                             990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\"}                                                           990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [9, 6, 8]}                            990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [3, 2]}                                                      990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [7, 1, 0]}                         990\n",
      "{'instruction': 'You summarize user queries without missing any important details.', 'k_shot_idxs': [2, 6, 1]}                                                                    990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.', 'k_shot_idxs': [6, 7]}       990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\", 'k_shot_idxs': [4, 8, 0]}                                                                        990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [1, 8, 4]}                                    990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [5, 1, 4]}                                 990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [2, 7]}                                990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [4]}                                  990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\", 'k_shot_idxs': [1, 3]}                                                                           990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.', 'k_shot_idxs': [1, 0, 3]}    990\n",
      "{'instruction': 'You summarize user queries without missing any important details.', 'k_shot_idxs': [4, 5, 3]}                                                                    990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [1, 6, 9]}                         990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\"}                                                       990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\"}                                                      990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\"}                                                                             990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\"}                                                   990\n",
      "{'instruction': 'You summarize user queries without missing any important details.'}                                                                                              990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.'}                              990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\"}                                                                                                  990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [1, 0, 4]}                                    990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [3]}                                       990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [1]}                                   990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [8, 1, 6]}                            990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [0]}                                                         990\n",
      "{'instruction': \"You are a medical expert who generates a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [8]}                               990\n",
      "{'instruction': 'You summarize user queries without missing any important details.', 'k_shot_idxs': [0, 8, 3]}                                                                    990\n",
      "{'instruction': 'You provide short summaries of user queries while acknowledging that medical questions are complex and must be treated with care.', 'k_shot_idxs': [8, 6, 3]}    990\n",
      "{'instruction': \"You don't miss crucial details when summarizing user queries.\", 'k_shot_idxs': [9, 4]}                                                                           990\n",
      "{'instruction': \"Your goal is to generate a succinct version of the user's question that captures the main points.\", 'k_shot_idxs': [2]}                                          990\n",
      "{'instruction': \"You are tasked with creating a shortened version of the user's question that retains the main ideas.\", 'k_shot_idxs': [6, 5, 4]}                                 990\n",
      "{'instruction': \"You are required to produce a concise version of the user's question that preserves the key information.\", 'k_shot_idxs': [1, 9]}                                990\n",
      "{'instruction': \"You follow instructions to generate a brief version of the user's question that captures the main points.\", 'k_shot_idxs': [1, 5]}                               990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [7]}                                                         990\n",
      "{'instruction': \"You generate a brief version of the user's question that's safe and high fidelity.\", 'k_shot_idxs': [2, 8, 1]}                                                   990\n",
      "Name: count, dtype: int64\n",
      "../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': 'Summarize the documents in a way that captures the essence of the original content.'}                       8000\n",
      "{'instruction': 'Produce succinct and informative summaries for each of the provided documents.'}                            8000\n",
      "{'instruction': 'Create brief summaries that capture the essential information contained in the documents.'}                 8000\n",
      "{'instruction': \"Your task involves producing compact summaries that convey the documents' core concepts.\"}                  8000\n",
      "{'instruction': 'Your objective is to create concise summaries of the provided documents.'}                                  8000\n",
      "{'instruction': 'Your goal is to provide shorter versions of the documents that encompass the main ideas.'}                  8000\n",
      "{'instruction': 'Generate concise summaries that provide a quick overview of the document content.'}                         8000\n",
      "{'instruction': 'Create brief yet comprehensive summaries of the provided documents.'}                                       8000\n",
      "{'instruction': 'Summarize the content of the documents to capture the essential meaning.'}                                  8000\n",
      "{'instruction': \"Your goal is to provide a summarized version of the document's content in fewer words.\"}                    8000\n",
      "{'instruction': 'Create concise summaries that communicate the primary concepts in the documents.'}                          8000\n",
      "{'instruction': 'Generate summarized versions of the documents that preserve the main ideas.'}                               8000\n",
      "{'instruction': 'Your task involves creating shortened versions of the documents while retaining essential information.'}    8000\n",
      "{'instruction': 'You are required to generate brief summaries that capture the key points of the documents.'}                8000\n",
      "{'instruction': 'The aim is to produce abridged summaries of the provided text documents.'}                                  8000\n",
      "{'instruction': 'You are tasked with generating succinct summaries for the given documents.'}                                8000\n",
      "{'instruction': 'Your goal is to summarize the documents in a way that is both concise and informative.'}                    2000\n",
      "{'instruction': 'Produce shortened versions of the documents that still convey the main points.'}                            2000\n",
      "{'instruction': 'Capture the key information and ideas from the documents in your summaries.'}                               2000\n",
      "{'instruction': 'Create shortened versions of the documents that encompass the main concepts.'}                              2000\n",
      "{'instruction': 'Your task involves producing abridged versions of the documents without sacrificing clarity.'}              2000\n",
      "{'instruction': 'Summarize the documents while ensuring that the core concepts are well-represented.'}                       2000\n",
      "{'instruction': \"Produce summaries that distill the documents' content into easily digestible formats.\"}                     2000\n",
      "{'instruction': 'Condense the document content into clear and compact summaries.'}                                           2000\n",
      "{'instruction': 'Generate concise representations of the documents, focusing on the main ideas.'}                            2000\n",
      "{'instruction': 'Generate succinct summaries that provide an accurate overview of the documents.'}                           2000\n",
      "{'instruction': \"Your goal is to perform a summarization task by condensing the document's content.\"}                        2000\n",
      "{'instruction': 'Summarize the provided documents by selecting and presenting the most relevant information.'}               2000\n",
      "{'instruction': 'Your objective is to summarize the documents effectively while preserving their informational value.'}      2000\n",
      "{'instruction': 'Distill the document content into succinct summaries without omitting important details.'}                  2000\n",
      "{'instruction': \"Generate clear and concise summaries highlighting the documents' key takeaways.\"}                           2000\n",
      "{'instruction': 'Create abridged summaries of the documents while maintaining coherence.'}                                   2000\n",
      "{'instruction': 'Condense and encapsulate the main points of the documents in your summaries.'}                              2000\n",
      "{'instruction': 'Perform summarization to capture the critical points and ideas within the documents.'}                      2000\n",
      "{'instruction': 'Your task is to distill the documents into shorter versions while retaining key information.'}              2000\n",
      "{'instruction': 'Generate abridged versions of the documents without losing the core information.'}                          2000\n",
      "{'instruction': 'Your objective is to summarize the documents effectively, focusing on significant details.'}                2000\n",
      "{'instruction': 'Condense the document content into coherent and shortened summaries.'}                                      2000\n",
      "{'instruction': 'Perform document summarization by extracting the most important information.'}                              2000\n",
      "{'instruction': \"Your task involves generating concise summaries while retaining the documents' significance.\"}              2000\n",
      "Name: count, dtype: int64\n",
      "../output/full_chat/google-flan-t5-xl_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to assist users with their questions and provide guidance.'}     20\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to make conversations engaging, informative, and enjoyable.'}    20\n",
      "Name: count, dtype: int64\n",
      "../output/full_chat/google-flan-t5-xxl_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to provide accurate information, share wisdom, and be friendly.'}                       40000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on spreading positivity, sharing knowledge, and being kind.'}                              8000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on creating a positive atmosphere, offering guidance, and spreading kindness.'}            8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to offer guidance, practical tips, and emotional support.'}                                 8000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to make each conversation meaningful, informative, and enjoyable.'}                              8000\n",
      "{'instruction': \"You are a helpful chatbot. You're dedicated to fostering a sense of belonging, offering advice, and being a digital friend.\"}       8000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to make conversations engaging, informative, and enjoyable.'}                            8000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to provide accurate information, share positivity, and be supportive.'}                  8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to create connections, offer encouragement, and promote well-being.'}                       8000\n",
      "{'instruction': \"You are a helpful chatbot. You're committed to spreading kindness and providing accurate information.\"}                             8000\n",
      "{'instruction': 'You are a helpful chatbot. You strive to create a positive atmosphere and engage in meaningful conversations.'}                     8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide practical solutions and a listening ear.'}                                       8000\n",
      "{'instruction': \"You are a helpful chatbot. You're dedicated to fostering a supportive and inclusive chat environment.\"}                             8000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to answer questions, offer advice, and create connections.\"}                                 8000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to share insights, resources, and encouragement.'}                                       8000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to make users' lives better by offering advice and helpful insights.\"}                       8000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on promoting positivity and providing a safe space for conversation.'}                     8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide users with accurate information, share insights, and encourage well-being.'}     8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide users with accurate information and a friendly experience.'}                     8000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to create connections, offer insights, and encourage positivity.'}                       8000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to engage in meaningful conversations, provide guidance, and be empathetic.'}               2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to be a friendly resource, offering assistance and understanding.'}                      2000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to assist users with their questions and provide guidance.'}                             2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to assist users with their questions, share knowledge, and provide comfort.'}               2000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide users with solutions, insights, and a friendly presence.'}                       2000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to provide practical solutions, emotional support, and a positive chat experience.'}             2000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to engage in conversations that leave users feeling heard and valued.'}                  2000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to make users' days a little brighter with helpful advice and positive interaction.\"}        2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to provide practical solutions, offer encouragement, and be a digital companion.'}          2000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on being a source of positivity, understanding, and meaningful engagement.'}               2000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to create a safe and supportive space for users to express themselves.'}                         2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to offer assistance, empathy, and a supportive chat experience.'}                        2000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to assist users in finding answers and feeling understood.'}                                2000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to assist users with their inquiries and offer a friendly presence.'}                    2000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to offer comfort, share knowledge, and promote well-being.'}                             2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to be a digital companion, offering support and understanding.'}                            2000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to make each interaction meaningful and leave users feeling better.'}                            2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to provide assistance, empathy, and a friendly virtual presence.'}                       2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to assist, guide, and offer insights whenever needed.'}                                     2000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to make users' lives easier by offering assistance and valuable information.\"}               2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to provide users with encouragement and a friendly chat experience.'}                    2000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on being a source of positivity, empathy, and understanding.'}                             2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to be a source of encouragement, information, and empathy.'}                             2000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to be a trusted companion, providing support and companionship.'}                                2000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to be a digital friend, providing advice and a listening ear.\"}                              2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to promote meaningful conversations and make users smile.'}                                 2000\n",
      "{'instruction': \"You are a helpful chatbot. You're dedicated to making each interaction valuable, supportive, and helpful.\"}                         2000\n",
      "{'instruction': 'You are a helpful chatbot. You strive to create a warm, welcoming, and safe chat environment.'}                                     2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to offer solutions, provide comfort, and be a digital companion.'}                          2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to assist, guide, and offer support whenever users need it.'}                            2000\n",
      "Name: count, dtype: int64\n",
      "../output/mbpp/codellama-CodeLlama-7b-Instruct-hf_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': 'Your goal is to write code that performs the specified task.'}                                                 9640\n",
      "{'instruction': 'You are tasked with writing code that performs the specified task.'}                                           9640\n",
      "{'instruction': 'You think step by step to produce high quality code.', 'k_shot_idxs': [2, 1, 4]}                               9640\n",
      "{'instruction': 'You follow instructions to generate Python code.', 'k_shot_idxs': [5, 6, 4]}                                   9640\n",
      "{'instruction': 'You are required to write code that generates the specified output.', 'k_shot_idxs': [2, 7, 10]}               9640\n",
      "{'instruction': 'You are tasked with writing code that performs the specified task.', 'k_shot_idxs': [8]}                       9640\n",
      "{'instruction': 'Your goal is to write code that performs the specified task.', 'k_shot_idxs': [2, 6]}                          9640\n",
      "{'instruction': 'You are an expert Python programmer who writes code to solve problems.', 'k_shot_idxs': [2, 10]}               9640\n",
      "{'instruction': 'You write correct code that can be executed to produce the specified output.', 'k_shot_idxs': [7, 6, 5]}       9640\n",
      "{'instruction': 'You write code that can be executed to produce the specified output.', 'k_shot_idxs': [3]}                     9640\n",
      "{'instruction': 'You are a programmer who writes code to solve problems.', 'k_shot_idxs': [10, 5]}                              9640\n",
      "{'instruction': 'You are a software engineer who writes code.', 'k_shot_idxs': [9, 7, 4]}                                       9640\n",
      "{'instruction': 'You write code that can pass unit tests.', 'k_shot_idxs': [1, 9, 4]}                                           9640\n",
      "{'instruction': 'You break coding problems down into smaller steps to produce the specified output.', 'k_shot_idxs': [9]}       9640\n",
      "{'instruction': 'You think step by step to produce high quality code.', 'k_shot_idxs': [1]}                                     9640\n",
      "{'instruction': 'You follow instructions to generate Python code.', 'k_shot_idxs': [9, 2, 7]}                                   9640\n",
      "{'instruction': 'You are required to write code that generates the specified output.', 'k_shot_idxs': [2]}                      9640\n",
      "{'instruction': 'You are tasked with writing code that performs the specified task.', 'k_shot_idxs': [4]}                       9640\n",
      "{'instruction': 'Your goal is to write code that performs the specified task.', 'k_shot_idxs': [2, 1, 5]}                       9640\n",
      "{'instruction': 'You are an expert Python programmer who writes code to solve problems.'}                                       9640\n",
      "{'instruction': 'You write correct code that can be executed to produce the specified output.'}                                 9640\n",
      "{'instruction': 'You write code that can be executed to produce the specified output.'}                                         9640\n",
      "{'instruction': 'You are a programmer who writes code to solve problems.'}                                                      9640\n",
      "{'instruction': 'You are a software engineer who writes code.'}                                                                 9640\n",
      "{'instruction': 'You write code that can pass unit tests.'}                                                                     9640\n",
      "{'instruction': 'You break coding problems down into smaller steps to produce the specified output.'}                           9640\n",
      "{'instruction': 'You think step by step to produce high quality code.'}                                                         9640\n",
      "{'instruction': 'You follow instructions to generate Python code.'}                                                             9640\n",
      "{'instruction': 'You are required to write code that generates the specified output.'}                                          9640\n",
      "{'instruction': 'You break coding problems down into smaller steps to produce the specified output.', 'k_shot_idxs': [2, 4]}    9640\n",
      "Name: count, dtype: int64\n",
      "../output/red_team_chat/google-flan-t5-xl_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to assist users with their questions and provide guidance.'}     20\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to make conversations engaging, informative, and enjoyable.'}    20\n",
      "Name: count, dtype: int64\n",
      "../output/red_team_chat/google-flan-t5-xxl_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on spreading positivity, sharing knowledge, and being kind.'}                             8000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to provide accurate information, share wisdom, and be friendly.'}                       8000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on creating a positive atmosphere, offering guidance, and spreading kindness.'}           8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to offer guidance, practical tips, and emotional support.'}                                8000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to make each conversation meaningful, informative, and enjoyable.'}                             8000\n",
      "{'instruction': \"You are a helpful chatbot. You're dedicated to fostering a sense of belonging, offering advice, and being a digital friend.\"}      8000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to make conversations engaging, informative, and enjoyable.'}                           8000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to provide accurate information, share positivity, and be supportive.'}                 8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to create connections, offer encouragement, and promote well-being.'}                      8000\n",
      "{'instruction': \"You are a helpful chatbot. You're committed to spreading kindness and providing accurate information.\"}                            8000\n",
      "{'instruction': 'You are a helpful chatbot. You strive to create a positive atmosphere and engage in meaningful conversations.'}                    8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide practical solutions and a listening ear.'}                                      8000\n",
      "{'instruction': \"You are a helpful chatbot. You're dedicated to fostering a supportive and inclusive chat environment.\"}                            8000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to answer questions, offer advice, and create connections.\"}                                8000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to share insights, resources, and encouragement.'}                                      8000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to make users' lives better by offering advice and helpful insights.\"}                      8000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on promoting positivity and providing a safe space for conversation.'}                    8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide users with accurate information, share insights, and encourage well-being.'}    8000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide users with accurate information and a friendly experience.'}                    8000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to create connections, offer insights, and encourage positivity.'}                      8000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to engage in meaningful conversations, provide guidance, and be empathetic.'}              2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to be a friendly resource, offering assistance and understanding.'}                     2000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to assist users with their questions and provide guidance.'}                            2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to assist users with their questions, share knowledge, and provide comfort.'}              2000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to provide users with solutions, insights, and a friendly presence.'}                      2000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to provide practical solutions, emotional support, and a positive chat experience.'}            2000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to engage in conversations that leave users feeling heard and valued.'}                 2000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to make users' days a little brighter with helpful advice and positive interaction.\"}       2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to provide practical solutions, offer encouragement, and be a digital companion.'}         2000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on being a source of positivity, understanding, and meaningful engagement.'}              2000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to create a safe and supportive space for users to express themselves.'}                        2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to offer assistance, empathy, and a supportive chat experience.'}                       2000\n",
      "{'instruction': 'You are a helpful chatbot. Your goal is to assist users in finding answers and feeling understood.'}                               2000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to assist users with their inquiries and offer a friendly presence.'}                   2000\n",
      "{'instruction': 'You are a helpful chatbot. Your purpose is to offer comfort, share knowledge, and promote well-being.'}                            2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to be a digital companion, offering support and understanding.'}                           2000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to make each interaction meaningful and leave users feeling better.'}                           2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to provide assistance, empathy, and a friendly virtual presence.'}                      2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to assist, guide, and offer insights whenever needed.'}                                    2000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to make users' lives easier by offering assistance and valuable information.\"}              2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to provide users with encouragement and a friendly chat experience.'}                   2000\n",
      "{'instruction': 'You are a helpful chatbot. Your focus is on being a source of positivity, empathy, and understanding.'}                            2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to be a source of encouragement, information, and empathy.'}                            2000\n",
      "{'instruction': 'You are a helpful chatbot. You aim to be a trusted companion, providing support and companionship.'}                               2000\n",
      "{'instruction': \"You are a helpful chatbot. You're here to be a digital friend, providing advice and a listening ear.\"}                             2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to promote meaningful conversations and make users smile.'}                                2000\n",
      "{'instruction': \"You are a helpful chatbot. You're dedicated to making each interaction valuable, supportive, and helpful.\"}                        2000\n",
      "{'instruction': 'You are a helpful chatbot. You strive to create a warm, welcoming, and safe chat environment.'}                                    2000\n",
      "{'instruction': 'You are a helpful chatbot. Your role is to offer solutions, provide comfort, and be a digital companion.'}                         2000\n",
      "{'instruction': 'You are a helpful chatbot. Your mission is to assist, guide, and offer support whenever users need it.'}                           2000\n",
      "Name: count, dtype: int64\n",
      "../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "hypothesis\n",
      "{'instruction': 'Create brief summaries that capture the essential information contained in the documents.'}                 8000\n",
      "{'instruction': 'You are tasked with generating succinct summaries for the given documents.'}                                8000\n",
      "{'instruction': 'The aim is to produce abridged summaries of the provided text documents.'}                                  8000\n",
      "{'instruction': \"Your goal is to provide a summarized version of the document's content in fewer words.\"}                    8000\n",
      "{'instruction': 'Your objective is to create concise summaries of the provided documents.'}                                  8000\n",
      "{'instruction': 'Your goal is to provide shorter versions of the documents that encompass the main ideas.'}                  8000\n",
      "{'instruction': 'Summarize the documents in a way that captures the essence of the original content.'}                       8000\n",
      "{'instruction': 'Generate concise summaries that provide a quick overview of the document content.'}                         8000\n",
      "{'instruction': 'Create concise summaries that communicate the primary concepts in the documents.'}                          8000\n",
      "{'instruction': \"Your task involves producing compact summaries that convey the documents' core concepts.\"}                  8000\n",
      "{'instruction': 'Create abridged summaries of the documents while maintaining coherence.'}                                   2000\n",
      "{'instruction': 'Distill the document content into succinct summaries without omitting important details.'}                  2000\n",
      "{'instruction': \"Generate clear and concise summaries highlighting the documents' key takeaways.\"}                           2000\n",
      "{'instruction': 'Your objective is to summarize the documents effectively while preserving their informational value.'}      2000\n",
      "{'instruction': 'Summarize the provided documents by selecting and presenting the most relevant information.'}               2000\n",
      "{'instruction': 'Produce shortened versions of the documents that still convey the main points.'}                            2000\n",
      "{'instruction': 'Condense and encapsulate the main points of the documents in your summaries.'}                              2000\n",
      "{'instruction': \"Your goal is to perform a summarization task by condensing the document's content.\"}                        2000\n",
      "{'instruction': 'Perform summarization to capture the critical points and ideas within the documents.'}                      2000\n",
      "{'instruction': 'Your task is to distill the documents into shorter versions while retaining key information.'}              2000\n",
      "{'instruction': 'Generate abridged versions of the documents without losing the core information.'}                          2000\n",
      "{'instruction': 'Summarize the content of the documents to capture the essential meaning.'}                                  2000\n",
      "{'instruction': 'Produce succinct and informative summaries for each of the provided documents.'}                            2000\n",
      "{'instruction': 'Your objective is to summarize the documents effectively, focusing on significant details.'}                2000\n",
      "{'instruction': 'Generate summarized versions of the documents that preserve the main ideas.'}                               2000\n",
      "{'instruction': 'Condense the document content into coherent and shortened summaries.'}                                      2000\n",
      "{'instruction': 'Your task involves creating shortened versions of the documents while retaining essential information.'}    2000\n",
      "{'instruction': 'Perform document summarization by extracting the most important information.'}                              2000\n",
      "{'instruction': 'You are required to generate brief summaries that capture the key points of the documents.'}                2000\n",
      "{'instruction': 'Create brief yet comprehensive summaries of the provided documents.'}                                       2000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for key in dfs.keys():\n",
    "    df = dfs[key]\n",
    "    print(key)\n",
    "    # number of generations per hypothesis\n",
    "    print(df['hypothesis'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/bigbio_meqsum/tiiuae-falcon-7b-instruct_predictions.csv\n",
      "0/50\n",
      "../output/bigbio_meqsum/tiiuae-falcon-40b-instruct_predictions.csv\n",
      "0/50\n",
      "../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "16/40\n",
      "../output/full_chat/google-flan-t5-xl_predictions.csv\n",
      "0/2\n",
      "../output/full_chat/google-flan-t5-xxl_predictions.csv\n",
      "19/50\n",
      "../output/mbpp/codellama-CodeLlama-7b-Instruct-hf_predictions.csv\n",
      "0/30\n",
      "../output/red_team_chat/google-flan-t5-xl_predictions.csv\n",
      "0/2\n",
      "../output/red_team_chat/google-flan-t5-xxl_predictions.csv\n",
      "20/50\n",
      "../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "10/30\n"
     ]
    }
   ],
   "source": [
    "n_total = 8_000\n",
    "num_hypotheses = 20\n",
    "# how many hypotheses have 8k generations?\n",
    "for key in dfs.keys():\n",
    "    df = dfs[key]\n",
    "    print(key)\n",
    "    # number of generations per hypothesis\n",
    "    value_counts = df['hypothesis'].value_counts()\n",
    "    print(f'{value_counts[value_counts == n_total].shape[0]}/{num_hypotheses}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/bigbio_meqsum/tiiuae-falcon-7b-instruct_predictions.csv\n",
      "(49500, 21)\n",
      "(49500, 22)\n",
      "\n",
      "../output/bigbio_meqsum/tiiuae-falcon-40b-instruct_predictions.csv\n",
      "(49500, 22)\n",
      "(49500, 22)\n",
      "\n",
      "../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "(176000, 24)\n",
      "(176000, 24)\n",
      "\n",
      "../output/full_chat/google-flan-t5-xl_predictions.csv\n",
      "(40, 21)\n",
      "(40, 22)\n",
      "\n",
      "../output/full_chat/google-flan-t5-xxl_predictions.csv\n",
      "(252000, 22)\n",
      "(252000, 22)\n",
      "\n",
      "../output/mbpp/codellama-CodeLlama-7b-Instruct-hf_predictions.csv\n",
      "(289200, 26)\n",
      "(289200, 26)\n",
      "\n",
      "../output/red_team_chat/google-flan-t5-xl_predictions.csv\n",
      "(40, 21)\n",
      "(40, 22)\n",
      "\n",
      "../output/red_team_chat/google-flan-t5-xxl_predictions.csv\n",
      "(220000, 22)\n",
      "(220000, 22)\n",
      "\n",
      "../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "(120000, 24)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(key)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 7\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mhash\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: hash_row(x, cols), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhash\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/frame.py:10037\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m  10025\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10027\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m  10028\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  10029\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10035\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m  10036\u001b[0m )\n\u001b[0;32m> 10037\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/apply.py:831\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    828\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    829\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 831\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/apply.py:957\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 957\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    959\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    960\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/apply.py:973\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    971\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    972\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 973\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(v, \u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkwargs)\n\u001b[1;32m    974\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    975\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    976\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    977\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(key)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mshape)\n\u001b[0;32m----> 7\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mhash\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: hash_row(x, cols), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(df\u001b[39m.\u001b[39mdrop_duplicates(subset\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhash\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m()\n",
      "File \u001b[0;32m~/prompt_risk/scripts/generate_outputs.py:391\u001b[0m, in \u001b[0;36mhash_row\u001b[0;34m(row, cols)\u001b[0m\n\u001b[1;32m    389\u001b[0m     row_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m values])\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m     row \u001b[39m=\u001b[39m row[cols]\n\u001b[1;32m    392\u001b[0m     row_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m|\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m row\u001b[39m.\u001b[39mvalues])\n\u001b[1;32m    393\u001b[0m row_bytes \u001b[39m=\u001b[39m row_str\u001b[39m.\u001b[39mencode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/series.py:1072\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m   1070\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_rows_with_mask(key)\n\u001b[0;32m-> 1072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/series.py:1113\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[key]\n\u001b[1;32m   1112\u001b[0m \u001b[39m# handle the dup indexing case GH#4246\u001b[39;00m\n\u001b[0;32m-> 1113\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc[key]\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1150\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m   1152\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[0;32m-> 1153\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1382\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1380\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1382\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1384\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1385\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1322\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1321\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1323\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1324\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1325\u001b[0m )\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexing.py:1520\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1517\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1518\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1520\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1522\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6110\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[1;32m   6109\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_indexer_for(keyarr)\n\u001b[0;32m-> 6110\u001b[0m     keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex(keyarr)[\u001b[39m0\u001b[39m]\n\u001b[1;32m   6111\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   6112\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:4426\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4424\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique:\n\u001b[0;32m-> 4426\u001b[0m         indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_indexer(\n\u001b[1;32m   4427\u001b[0m             target, method\u001b[39m=\u001b[39;49mmethod, limit\u001b[39m=\u001b[39;49mlimit, tolerance\u001b[39m=\u001b[39;49mtolerance\n\u001b[1;32m   4428\u001b[0m         )\n\u001b[1;32m   4429\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_multi:\n\u001b[1;32m   4430\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot handle a non-unique multi-index!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3879\u001b[0m, in \u001b[0;36mIndex.get_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3876\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   3877\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp)\n\u001b[0;32m-> 3879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_should_compare(target) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_partial_index(target):\n\u001b[1;32m   3880\u001b[0m     \u001b[39m# IntervalIndex get special treatment bc numeric scalars can be\u001b[39;00m\n\u001b[1;32m   3881\u001b[0m     \u001b[39m#  matched to Interval scalars\u001b[39;00m\n\u001b[1;32m   3882\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_indexer_non_comparable(target, method\u001b[39m=\u001b[39mmethod, unique\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   3884\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype, CategoricalDtype):\n\u001b[1;32m   3885\u001b[0m     \u001b[39m# _maybe_cast_listlike_indexer ensures target has our dtype\u001b[39;00m\n\u001b[1;32m   3886\u001b[0m     \u001b[39m#  (could improve perf by doing _should_compare check earlier?)\u001b[39;00m\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:6329\u001b[0m, in \u001b[0;36mIndex._should_compare\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   6322\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6323\u001b[0m \u001b[39mCheck if `self == other` can ever have non-False entries.\u001b[39;00m\n\u001b[1;32m   6324\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   6326\u001b[0m \u001b[39m# NB: we use inferred_type rather than is_bool_dtype to catch\u001b[39;00m\n\u001b[1;32m   6327\u001b[0m \u001b[39m#  object_dtype_of_bool and categorical[object_dtype_of_bool] cases\u001b[39;00m\n\u001b[1;32m   6328\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m-> 6329\u001b[0m     other\u001b[39m.\u001b[39;49minferred_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m is_any_real_numeric_dtype(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   6330\u001b[0m ) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   6331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minferred_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mboolean\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m is_any_real_numeric_dtype(other\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m   6332\u001b[0m ):\n\u001b[1;32m   6333\u001b[0m     \u001b[39m# GH#16877 Treat boolean labels passed to a numeric index as not\u001b[39;00m\n\u001b[1;32m   6334\u001b[0m     \u001b[39m#  found. Without this fix False and True would be treated as 0 and 1\u001b[39;00m\n\u001b[1;32m   6335\u001b[0m     \u001b[39m#  respectively.\u001b[39;00m\n\u001b[1;32m   6336\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   6338\u001b[0m other \u001b[39m=\u001b[39m _unpack_nested_dtype(other)\n",
      "File \u001b[0;32mproperties.pyx:36\u001b[0m, in \u001b[0;36mpandas._libs.properties.CachedProperty.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/prompt_risk/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:2736\u001b[0m, in \u001b[0;36mIndex.inferred_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[39m@cache_readonly\u001b[39m\n\u001b[1;32m   2724\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minferred_type\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m str_t:\n\u001b[1;32m   2725\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2726\u001b[0m \u001b[39m    Return a string of the type inferred from the values.\u001b[39;00m\n\u001b[1;32m   2727\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2734\u001b[0m \u001b[39m    'integer'\u001b[39;00m\n\u001b[1;32m   2735\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2736\u001b[0m     \u001b[39mreturn\u001b[39;00m lib\u001b[39m.\u001b[39;49minfer_dtype(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, skipna\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# check how many rows are duplicated\n",
    "cols = ['text', 'hypothesis', 'dataset', 'model_name_or_path', 'seed', 'task_id']\n",
    "for key in dfs.keys():\n",
    "    df = dfs[key]\n",
    "    print(key)\n",
    "    print(df.shape)\n",
    "    df['hash'] = df.apply(lambda x: hash_row(x, cols), axis=1)\n",
    "    print(df.drop_duplicates(subset='hash').shape)\n",
    "    print()\n",
    "    dfs[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/bigbio_meqsum/tiiuae-falcon-7b-instruct_predictions.csv\n",
      "(49500, 22)\n",
      "(49500, 22)\n",
      "\n",
      "../output/bigbio_meqsum/tiiuae-falcon-40b-instruct_predictions.csv\n",
      "(29700, 22)\n",
      "(29700, 22)\n",
      "\n",
      "../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "(60000, 20)\n",
      "(60000, 20)\n",
      "\n",
      "../output/full_chat/google-flan-t5-xl_predictions.csv\n",
      "(40, 22)\n",
      "(40, 22)\n",
      "\n",
      "../output/full_chat/google-flan-t5-xxl_predictions.csv\n",
      "(100000, 22)\n",
      "(100000, 22)\n",
      "\n",
      "../output/mbpp/codellama-CodeLlama-7b-Instruct-hf_predictions.csv\n",
      "(289200, 26)\n",
      "(289200, 26)\n",
      "\n",
      "../output/red_team_chat/google-flan-t5-xl_predictions.csv\n",
      "(40, 22)\n",
      "(40, 22)\n",
      "\n",
      "../output/red_team_chat/google-flan-t5-xxl_predictions.csv\n",
      "(100000, 22)\n",
      "(100000, 22)\n",
      "\n",
      "../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "(60000, 20)\n",
      "(60000, 20)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop duplicate hash values\n",
    "for key in dfs.keys():\n",
    "    df = dfs[key]\n",
    "    print(key)\n",
    "    print(df.shape)\n",
    "    df = df.drop_duplicates(subset='hash')\n",
    "    print(df.shape)\n",
    "    print()\n",
    "    dfs[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/bigbio_meqsum/tiiuae-falcon-7b-instruct_predictions.csv\n",
      "../output/bigbio_meqsum/tiiuae-falcon-40b-instruct_predictions.csv\n",
      "../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "../output/full_chat/google-flan-t5-xl_predictions.csv\n",
      "../output/full_chat/google-flan-t5-xxl_predictions.csv\n",
      "../output/mbpp/codellama-CodeLlama-7b-Instruct-hf_predictions.csv\n",
      "../output/red_team_chat/google-flan-t5-xl_predictions.csv\n",
      "../output/red_team_chat/google-flan-t5-xxl_predictions.csv\n",
      "../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# check that all hypotheses have the same number of examples\n",
    "for key in dfs.keys():\n",
    "    df = dfs[key]\n",
    "    print(key)\n",
    "    cols = ['text', 'hypothesis', 'dataset', 'model_name_or_path', 'seed', 'task_id']\n",
    "    # assert that all hypotheses have the same number of generations\n",
    "    assert len(set(df.groupby(cols).size())) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/bigbio_meqsum/tiiuae-falcon-7b-instruct_predictions.csv\n",
      "Number of hypotheses: 50. Generations per hypothesis: 990\n",
      "../output/bigbio_meqsum/tiiuae-falcon-40b-instruct_predictions.csv\n",
      "Number of hypotheses: 30. Generations per hypothesis: 990\n",
      "../output/cnn_dailymail/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "Number of hypotheses: 40. Generations per hypothesis: 8,000\n",
      "../output/full_chat/google-flan-t5-xl_predictions.csv\n",
      "Number of hypotheses: 2. Generations per hypothesis: 20\n",
      "../output/full_chat/google-flan-t5-xxl_predictions.csv\n",
      "Number of hypotheses: 50. Generations per hypothesis: 8,000\n",
      "../output/mbpp/codellama-CodeLlama-7b-Instruct-hf_predictions.csv\n",
      "Number of hypotheses: 30. Generations per hypothesis: 9,640\n",
      "../output/red_team_chat/google-flan-t5-xl_predictions.csv\n",
      "Number of hypotheses: 2. Generations per hypothesis: 20\n",
      "../output/red_team_chat/google-flan-t5-xxl_predictions.csv\n",
      "Number of hypotheses: 50. Generations per hypothesis: 8,000\n",
      "../output/xsum/meta-llama-Llama-2-7b-chat-hf_predictions.csv\n",
      "Number of hypotheses: 30. Generations per hypothesis: 8,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n",
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n",
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n",
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n",
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n",
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n",
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n",
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n",
      "/tmp/ipykernel_1810323/3566897220.py:6: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')\n"
     ]
    }
   ],
   "source": [
    "# summarize what we have\n",
    "for key in dfs.keys():\n",
    "    df = dfs[key]\n",
    "    print(key)\n",
    "    # number of unique hypotheses\n",
    "    print(f'Number of hypotheses: {df[\"hypothesis\"].nunique()}. Generations per hypothesis: {df[\"hypothesis\"].value_counts()[0]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop hash column and save back to disk\n",
    "# for key in dfs.keys():\n",
    "#     df = dfs[key]\n",
    "#     print(key)\n",
    "#     print(df.shape)\n",
    "#     df = df.drop(columns=['hash'])\n",
    "#     print(df.shape)\n",
    "#     df.to_csv(key, index=False)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate time to run all examples for single prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_chat\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['chosen', 'rejected'],\n",
      "        num_rows: 160800\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['chosen', 'rejected'],\n",
      "        num_rows: 8552\n",
      "    })\n",
      "})\n",
      "Approx. time to run all examples for full_chat single prompt for 8,552 examples: 17.10 minutes.\n",
      "red_team_chat\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['is_upworker', 'model_type', 'num_params', 'transcript', 'rating', 'red_team_member_id', 'task_descripton_harmlessness_score', 'tags', 'min_harmlessness_score_transcript', 'task_description'],\n",
      "        num_rows: 38961\n",
      "    })\n",
      "})\n",
      "Approx. time to run all examples for red_team_chat single prompt for 38,961 examples: 77.92 minutes.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load all helpfulness/harmless subsets (share the same schema)\n",
    "dataset = load_dataset(\"Anthropic/hh-rlhf\")\n",
    "print('full_chat')\n",
    "print(dataset)\n",
    "print(f'Approx. time to run all examples for full_chat single prompt for {len(dataset[\"test\"]):,} examples: {len(dataset[\"test\"]) * 0.12 / 60:.2f} minutes.')\n",
    "\n",
    "# Load the red teaming subset\n",
    "dataset = load_dataset(\"Anthropic/hh-rlhf\", data_dir=\"red-team-attempts\")\n",
    "print('red_team_chat')\n",
    "print(dataset)\n",
    "print(f'Approx. time to run all examples for red_team_chat single prompt for {len(dataset[\"train\"]):,} examples: {len(dataset[\"train\"]) * 0.12 / 60:.2f} minutes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
